{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Principal Component Analysis\n",
    "### Spring 2024, Week 9\n",
    "<hr>\n",
    "Learning Objectives:\n",
    "\n",
    "  - Understand motivations of dimension reduction\n",
    "  - Discuss applications towards data visualization and data exxploration\n",
    "  - Interpret the results of a principal component analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr24/week9_principalcomponentanalysis.git\n",
    "!mkdir ./data\n",
    "!cp week9_principalcomponentanalysis/data/* ./data\n",
    "!pip install palmerpenguins\n",
    "!pip install umap-learn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from palmerpenguins import load_penguins\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (8,8)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set(font_scale=1.5, rc={'figure.figsize':FIG_SIZE}) \n",
    "sns.set_style()\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we're going to generate a toy dataset\n",
    "\n",
    "Notice the direction where the most variance occurs. In order to solve for these directions, we calculate the eigenvectors of the covariance matrix and plot it over the original data.\n",
    "\n",
    "This process is distinct from linear regression. In linear regression we are optimizing a response variable. In PCA there is no labelled data and we are optimizing across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_pca():\n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "    plt.scatter(X[:, 0], X[:, 1])\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "\n",
    "    # plot data\n",
    "    plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "    for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "        v = vector * 3 * np.sqrt(length)\n",
    "        draw_vector(pca.mean_, pca.mean_ + v)\n",
    "    plt.axis('equal');\n",
    "    plt.show()\n",
    "\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    color='k',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "example_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "- What would these vectors look like if we did not standardize the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- Please answer question 10 in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate System\n",
    "Now that we have the eigenvectors, we can do two things with them.\n",
    "First, we're going to look at using them as a new coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinatesystem_example():\n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "    pca = PCA(n_components=2, whiten=True)\n",
    "    pca.fit(X)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.15)\n",
    "\n",
    "    # plot data\n",
    "    ax[0].scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "    for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "        v = vector * 3 * np.sqrt(length)\n",
    "        draw_vector(pca.mean_, pca.mean_ + v, ax=ax[0])\n",
    "    ax[0].axis('equal');\n",
    "    ax[0].set(xlabel='x1', ylabel='x2', title='Raw Data')\n",
    "\n",
    "    # plot principal components\n",
    "    X_pca = pca.transform(X)\n",
    "    ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.2)\n",
    "    draw_vector([0, 0], [0, 3], ax=ax[1])\n",
    "    draw_vector([0, 0], [3, 0], ax=ax[1])\n",
    "    ax[1].axis('equal')\n",
    "    ax[1].set(xlabel='Principal component 1', ylabel='Principal component 2',\n",
    "              title='Transformed Data',\n",
    "              xlim=(-5, 5), ylim=(-3, 3.1))\n",
    "coordinatesystem_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "- Discuss the spread of the raw data in 2D. How does this compare to the spread of the data in the new coordinate system?\n",
    "\n",
    "ASSIGNMENT QUESTION:\n",
    "- Please answer question 11 in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "The other option we have is to simply use one principal component, and represent our data with one vector rather than two. What does this accomplish? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_example():\n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "    pca = PCA(n_components=2, whiten=True)\n",
    "    pca.fit(X)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.15)\n",
    "\n",
    "    # plot data\n",
    "    ax[0].scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "    ax[0].axis('equal');\n",
    "    ax[0].set(xlabel='x', ylabel='y', title='input')\n",
    "\n",
    "    # plot principal components\n",
    "    pca = PCA(n_components=1, whiten=True)\n",
    "    pca.fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "    X_new = pca.inverse_transform(X_pca)\n",
    "    ax[1].scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "    ax[1].scatter(X_new[:, 0], X_new[:, 1], color=\"blue\", alpha=0.8)\n",
    "    ax[1].axis('equal')\n",
    "    ax[1].set(xlabel='x', ylabel='y',\n",
    "              title='projected data (First PC)')\n",
    "    \n",
    "projection_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerformPCA(X, n_dimensions=10, plot=True, include_variance=True, fig_width = 10):\n",
    "    \"\"\"\n",
    "    Uses sklearn PCA tool to perform PCA.\n",
    "    Input:\n",
    "    X: Pandas DataFrame or NumPy Array of features\n",
    "    n_dimensions: Number of principal components to fit\n",
    "    plot: Whether to plot the scree plot\n",
    "    include_variance: Whether to include variance explained in the column names\n",
    "\n",
    "    Output:\n",
    "    X_pca: Pandas dataframe with column titles of PC1,...,PCn including variance explained in labels (optional)\n",
    "    column_names: List of column names created\n",
    "    \"\"\"\n",
    "    # Standardize the data\n",
    "    X_standardized = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Create PCA object and fit to standardized data\n",
    "    pca = PCA(n_components=n_dimensions)\n",
    "    pca.fit(X_standardized)\n",
    "    \n",
    "    # Transform data into principal components\n",
    "    X_pca_array = pca.transform(X_standardized)\n",
    "    \n",
    "    # Conditionally create column names incorporating the variance explained\n",
    "    if include_variance:\n",
    "        column_names = [\n",
    "            'PC{} ({:.1f}%)'.format(i + 1, var_exp * 100) \n",
    "            for i, var_exp in enumerate(pca.explained_variance_ratio_)\n",
    "        ]\n",
    "    else:\n",
    "        column_names = ['PC{}'.format(i + 1) for i in range(n_dimensions)]\n",
    "    \n",
    "    # Create DataFrame with new column names\n",
    "    X_pca = pd.DataFrame(X_pca_array, columns=column_names)\n",
    "    \n",
    "    # Optionally plot the cumulative variance explained in a scree plot\n",
    "    if plot:\n",
    "        plt.figure(figsize=(fig_width, 6))\n",
    "        plt.plot(column_names, np.cumsum(pca.explained_variance_ratio_), 'o--')\n",
    "        plt.title('Scree Plot of Explained Variance', fontsize=14)\n",
    "        plt.xlabel('Principal Components', fontsize=12)\n",
    "        plt.ylabel('Cumulative Variance Explained', fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return X_pca, column_names  # Correctly return both the DataFrame and the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are going to explore a couple datasets that we've looked at before with PCA\n",
    "We **could** plot all of our data against each other, and that usually makes sense for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins=load_penguins()\n",
    "penguins.dropna(inplace=True)\n",
    "features=[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\",\"body_mass_g\"]\n",
    "label='species'\n",
    "_ = sns.pairplot(penguins, vars=features, corner=True, hue=\"species\", markers=[\"o\", \"s\", \"D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can determine the principal components of the data and project our data onto the first two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_X = penguins[features]\n",
    "penguins_y = penguins[label]\n",
    "penguins_PCA_df, column_names = PerformPCA(penguins_X, n_dimensions=4, include_variance=False)\n",
    "penguins_PCA_df = penguins_PCA_df.join(penguins_y)\n",
    "\n",
    "# Plot using seaborn with updated axis labels\n",
    "sns.scatterplot(\n",
    "    x=column_names[0],  # Use the column name for PC1\n",
    "    y=column_names[1],  # Use the column name for PC2\n",
    "    hue='species',\n",
    "    style='species',\n",
    "    markers=[\"o\", \"s\", \"D\"],\n",
    "    data=penguins_PCA_df\n",
    ")\n",
    "plt.title('PCA of Penguin Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTION:\n",
    "- Please answer questions 12 - 15 in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use box plots to visualize the distribution of different penguin species along the first two principal components by projecting the dataset onto each principal component and plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.boxplot(x=\"species\", y=\"PC1\", hue=\"species\",\n",
    "                 data=penguins_PCA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.boxplot(x=\"species\", y=\"PC2\", hue=\"species\",\n",
    "                 data=penguins_PCA_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how this compares to a tSNE plot and a UMAP plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def PerformTSNE(X, n_dimensions=2, perplexity=30, plot=True, labels=None):\n",
    "    \"\"\"\n",
    "    Uses sklearn TSNE tool to perform t-SNE\n",
    "    input:\n",
    "    X: Pandas DataFrame or Numpy Array of features\n",
    "    n_dimensions: Number of dimensions to reduce to\n",
    "    perplexity: Perplexity parameter for t-SNE\n",
    "    labels: Optional Pandas Series or Numpy Array of labels for plotting\n",
    "\n",
    "    output:\n",
    "    X_tsne: Pandas DataFrame with column titles of t-SNE1, ..., t-SNEn\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=n_dimensions, perplexity=perplexity, random_state=42)\n",
    "    X_tsne_array = tsne.fit_transform(X)\n",
    "    column_names = ['t-SNE{}'.format(i+1) for i in range(n_dimensions)]\n",
    "    X_tsne = pd.DataFrame(X_tsne_array, columns=column_names)\n",
    "\n",
    "    if plot:\n",
    "        if labels is not None:\n",
    "            sns.scatterplot(x='t-SNE1', y='t-SNE2', hue=labels, data=X_tsne)\n",
    "            plt.title('t-SNE Scatter Plot', fontsize=14)\n",
    "            plt.show()\n",
    "\n",
    "    return X_tsne\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def PerformUMAP(X, n_dimensions=2, n_neighbors=15, min_dist=0.1, plot=True, labels=None):\n",
    "    \"\"\"\n",
    "    Uses umap-learn tool to perform UMAP\n",
    "    input:\n",
    "    X: Pandas DataFrame or Numpy Array of features\n",
    "    n_dimensions: Number of dimensions to reduce to\n",
    "    n_neighbors: Number of neighbors parameter for UMAP\n",
    "    min_dist: Minimum distance parameter for UMAP\n",
    "    labels: Optional Pandas Series or Numpy Array of labels for plotting\n",
    "\n",
    "    output:\n",
    "    X_umap: Pandas DataFrame with column titles of UMAP1, ..., UMAPn\n",
    "    \"\"\"\n",
    "    reducer = umap.UMAP(n_components=n_dimensions, n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)\n",
    "    X_umap_array = reducer.fit_transform(X)\n",
    "    column_names = ['UMAP{}'.format(i+1) for i in range(n_dimensions)]\n",
    "    X_umap = pd.DataFrame(X_umap_array, columns=column_names)\n",
    "\n",
    "    if plot:\n",
    "        if labels is not None:\n",
    "            sns.scatterplot(x='UMAP1', y='UMAP2', hue=labels, data=X_umap)\n",
    "            plt.title('UMAP Scatter Plot', fontsize=14)\n",
    "            plt.show()\n",
    "\n",
    "    return X_umap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "[t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) is a powerful non-linear technique for dimensionality reduction for visualizing high-dimensional datasets. It works by converting similarities between data points to [joint probabilities](https://en.wikipedia.org/wiki/Joint_probability_distribution) and trying to minimize the [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between the joint probabilities of the low-dimensional embedding and the high-dimensional data. This approach helps t-SNE excel at creating visually compelling clusterings and layouts where similar data points are modeled by nearby points and dissimilar data points are modeled by distant points. Its effectiveness, however, can depend significantly on the correct setting of its perplexity parameter, which roughly determines how to balance attention between local and global aspects of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "penguins_TSNE_df = PerformTSNE(penguins_X, n_dimensions=2)\n",
    "penguins_TSNE_df = penguins_TSNE_df.join(penguins_y)\n",
    "\n",
    "sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='species', data=penguins_TSNE_df, style='species', markers=[\"o\", \"s\", \"D\"])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"species\", y=\"t-SNE1\", hue=\"species\", data=penguins_TSNE_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"species\", y=\"t-SNE2\", hue=\"species\", data=penguins_TSNE_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of UMAP (Uniform Manifold Approximation and Projection)\n",
    "\n",
    "[UMAP](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection) is another non-linear technique for dimensionality reduction. It operates by constructing a high-dimensional graph representing the manifold structure of the data and then optimally laying out this graph in a lower-dimensional space. This process involves approximating the geometric structure of the data through local manifold approximations and fuzzy set theory. UMAP is particularly effective at preserving both local and global data structures, making it suitable for a broad range of applications. Like t-SNE, the performance of UMAP can be influenced by parameters, notably the number of neighbors and the minimum distance between points in the low-dimensional space. These parameters help control how UMAP balances the emphasis on local versus global features of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "penguins_UMAP_df = PerformUMAP(penguins_X, n_dimensions=2)\n",
    "penguins_UMAP_df = penguins_UMAP_df.join(penguins_y)\n",
    "\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='species', data=penguins_UMAP_df, style='species', markers=[\"o\", \"s\", \"D\"])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"species\", y=\"UMAP1\", hue=\"species\", data=penguins_UMAP_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"species\", y=\"UMAP2\", hue=\"species\", data=penguins_UMAP_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "- What are key difference in the transformed data across these three approaches?\n",
    "- What are similarities in the transformed data across these three approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to look at our trusty breast cancer dataset\n",
    "\n",
    "Remember, we could build fairly effective classification models with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cancer_raw = load_breast_cancer()\n",
    "print(cancer_raw.DESCR)\n",
    "tumor_features = pd.DataFrame(cancer_raw.data, columns=cancer_raw.feature_names)\n",
    "tumor = pd.DataFrame(cancer_raw.target, columns=['tumor'])\n",
    "tumor_nominal = tumor.replace({'tumor': {0: 'benign', 1: 'malignant'}})\n",
    "cancer_df = pd.concat([tumor_features, tumor_nominal], axis=1)\n",
    "tumor_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the tumor features\n",
    "PCA_df, column_names = PerformPCA(tumor_features, n_dimensions=30, include_variance=True, fig_width=14) \n",
    "# PCA_df, column_names = PerformPCA(tumor_features, n_dimensions=30, include_variance=True, plot=False)  # Unpack the tuple\n",
    "PCA_df = PCA_df.join(tumor_nominal) \n",
    "\n",
    "# Plot the results\n",
    "sns.scatterplot(x=column_names[0], y=column_names[1], style='tumor', hue='tumor', data=PCA_df, markers=True)\n",
    "plt.title('PCA of Breast Cancer Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTION\n",
    "- Please answer question 16 in the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if I plot different PCs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=column_names[3], y=column_names[4],style='tumor',hue='tumor',data=PCA_df,markers=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTION:\n",
    "- Please answer question 17 in the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare to tSNE and UMAP again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "tumor_TSNE_df = PerformTSNE(tumor_features, n_dimensions=2)\n",
    "tumor_TSNE_df = tumor_TSNE_df.join(tumor_nominal)\n",
    "\n",
    "sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='tumor', data=tumor_TSNE_df, style='tumor', markers=True)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"tumor\", y=\"t-SNE1\", hue=\"tumor\", data=tumor_TSNE_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"tumor\", y=\"t-SNE2\", hue=\"tumor\", data=tumor_TSNE_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "tumor_UMAP_df = PerformUMAP(tumor_features, n_dimensions=2)\n",
    "tumor_UMAP_df = tumor_UMAP_df.join(tumor_nominal)\n",
    "\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='tumor', data=tumor_UMAP_df, style='tumor', markers=True)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"tumor\", y=\"UMAP1\", hue=\"tumor\", data=tumor_UMAP_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"tumor\", y=\"UMAP2\", hue=\"tumor\", data=tumor_UMAP_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTION:\n",
    "- Please answer question 18 in the assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
